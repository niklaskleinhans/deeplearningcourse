{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepl_project_cnnrnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQIDvk8JWdUiF82Hq+id6z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdyTcCT7RmLi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAgqrBUMTIc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Conv2D,BatchNormalization, MaxPooling2D, Dense, Activation, Reshape, Dropout, TimeDistributed\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras import optimizers\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_NS0UEommyC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_config = {\n",
        "    'cnn' : {\n",
        "        'batch_size' : 64,\n",
        "        'num_classes' : 4,\n",
        "        'num_epochs' : 300,\n",
        "        'padding_mode' : 'same', # same, constant\n",
        "        'padding_size' : 1000,\n",
        "        'learning_rate_min' : 0.000001,\n",
        "        'learning_rate_max' : 0.001,\n",
        "        'model_name': 'Audio_300_26_2DCNN_4L(64-32-32-32)_e300_57.h5'\n",
        "    },\n",
        "    'cnnlstm':{\n",
        "        'batch_size' : 64,\n",
        "        'num_classes' : 4,\n",
        "        'num_epochs' : 300,\n",
        "        'padding_mode' : 'same', #same, constant\n",
        "        'padding_size' : 1000,\n",
        "        'subseq_size' : 10,\n",
        "        'lstm_cells' : 26,\n",
        "        'learning_rate_min' : 0.000001,\n",
        "        'learning_rate_max' : 0.001,\n",
        "        'model_name': 'Audio_same1000_26_cnnlstm_2L2L_SGD_e300.h5'\n",
        "    }\n",
        "}\n",
        "\n",
        "config = model_config['cnnlstm']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi5DXEfn5qWl",
        "colab_type": "code",
        "cellView": "code",
        "colab": {}
      },
      "source": [
        "#@title Dataloader\n",
        "#@markdown create a dataloader do import the input data and export the predictions\n",
        "\n",
        "class KerasDataloader():\n",
        "    \"\"\"\n",
        "    Keras Dataloader\n",
        "    The data must be a json file with the following structure:\n",
        "    { \"0\" : {\"features\" : [[]] ,\n",
        "            \"activation\" : 0|1 ,\n",
        "            \"valence\" : 0|1},\n",
        "      \"1\" : ...}\n",
        "    }\n",
        "\n",
        "    Parameters\n",
        "    ------\n",
        "    filepath : str\n",
        "        path to the file location\n",
        "    filename : str\n",
        "        filename for the dataimport\n",
        "    traindata: bool\n",
        "        If True, the data will be split into train and test dataset with data and label lists.\n",
        "        if False, just a datalist will be created\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, filepath, filename, paddingsize, traindata=True):\n",
        "        self.filepath = filepath\n",
        "        self.filename = filename\n",
        "        self.traindata = traindata\n",
        "        self.padding_size = paddingsize\n",
        "        self.lookup = { (0,0): [1.0,0.0,0.0,0.0],\n",
        "                        (1,0): [0.0,1.0,0.0,0.0],\n",
        "                        (0,1): [0.0,0.0,1.0,0.0],\n",
        "                        (1,1): [0.0,0.0,0.0,1.0]\n",
        "                      }\n",
        "        self.data=[]\n",
        "        self.__load__()\n",
        "\n",
        "    def __load__(self):\n",
        "        data = {}\n",
        "        with open(self.filepath+self.filename) as jsonFile:\n",
        "            data = json.load(jsonFile)\n",
        "        for item in data:\n",
        "            if self.traindata:\n",
        "                self.data.append({'features': data[item]['features'], \n",
        "                                  'label': self.__onehot__(data[item]['valence'], data[item]['activation']) })\n",
        "            else:\n",
        "              self.data.append({'features': data[item]['features']})\n",
        "    \n",
        "    def __onehot__(self, valence, activation):\n",
        "        return self.lookup[(valence, activation)]\n",
        "        \n",
        "    def __onehot_rev__(self, value):\n",
        "        for label, onehot in self.lookup.items():\n",
        "            if np.argmax(onehot) == np.argmax(value):\n",
        "                return label[0], label[1]\n",
        "\n",
        "    def __pad__(self, array, mode):\n",
        "        topad = max(0,self.padding_size-array.shape[0])\n",
        "        \n",
        "        if mode == 'constant':\n",
        "            kwargs = {'pad_width' : ((0,topad),(0,0)),\n",
        "                      'mode' : 'constant',\n",
        "                      'constant_values' : 0,\n",
        "                    }\n",
        "        if mode == 'same':\n",
        "             kwargs = {'pad_width' : ((0,topad),(0,0)),\n",
        "                      'mode' : 'wrap'\n",
        "                    }\n",
        "        return np.pad(array, **kwargs)[:self.padding_size:]\n",
        "\n",
        "    def load_data(self, splitvalue=0.1):\n",
        "        \"\"\"\n",
        "        Function to load the input dataset\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        splitvalue : float\n",
        "            split value between 0 and 1. Represents the percentage of the test, train set ratio\n",
        "          \n",
        "        Return\n",
        "        ------\n",
        "        Tupel: Lists\n",
        "            (x_train, y_train), (x_val, y_val)\n",
        "        \n",
        "        \"\"\"\n",
        "        if self.traindata: \n",
        "            random.shuffle(self.data)\n",
        "        x_train = []\n",
        "        y_train = []\n",
        "        x_val = []\n",
        "        y_val = []\n",
        "        if self.traindata:\n",
        "            splitindex = int(len(self.data)*(1-splitvalue))\n",
        "            train_set, val_set = self.data[:splitindex], self.data[splitindex+1:]\n",
        "            for item in train_set:\n",
        "                #item['features'] = keras.preprocessing.sequence.pad_sequences(np.asarray(item['features']).transpose(), self.padding_size, padding='pre', value=0).transpose()\n",
        "                item['features'] = self.__pad__(np.asarray(item['features']), config['padding_mode'])\n",
        "                x_train.append(item['features'])\n",
        "                y_train.append(item['label'])\n",
        "            for item in val_set:\n",
        "                #item['features'] = keras.preprocessing.sequence.pad_sequences(np.asarray(item['features']).transpose(), self.padding_size, padding='pre', value=0).transpose()\n",
        "                item['features'] = self.__pad__(np.asarray(item['features']), config['padding_mode'])\n",
        "                x_val.append(item['features'])\n",
        "                y_val.append(item['label'])\n",
        "            \n",
        "        else:\n",
        "            for item in self.data:\n",
        "                #item['features'] = keras.preprocessing.sequence.pad_sequences(np.asarray(item['features']).transpose(), self.padding_size, padding='pre', value=0).transpose()\n",
        "                item['features'] = self.__pad__(np.asarray(item['features']), config['padding_mode'])\n",
        "                x_train.append(item['features'])\n",
        "        x_train=np.asarray(x_train)\n",
        "        y_train=np.asarray(y_train)\n",
        "        x_val=np.asarray(x_val)\n",
        "        y_val=np.asarray(y_val)\n",
        "        return (x_train, y_train), (x_val, y_val)\n",
        "\n",
        "    def save_predictions(self, predictions):\n",
        "        \"\"\"\n",
        "        Function to save the model prediction in json file with structure:\n",
        "        { \"0\" : {\"features\" : [[]]},\n",
        "          \"1\" : ...}\n",
        "        }  \n",
        "    \n",
        "        Parameters\n",
        "        ----------\n",
        "        prediction : list\n",
        "            a list of the predicted classes\n",
        "          \n",
        "        \"\"\"\n",
        "        result = {}\n",
        "        for idx, prediction in enumerate(predictions):\n",
        "            valence, activation = self.__onehot_rev__(prediction)\n",
        "            result[str(idx)] = {'valence' : valence, 'activation': activation}\n",
        "        with open(self.filepath + 'results.json', 'w') as fp:\n",
        "            json.dump(result, fp)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl1ciBHvS85-",
        "colab_type": "code",
        "outputId": "00a5ea66-0132-4da4-b69a-0dd7eff27cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# load data\n",
        "dataloader = KerasDataloader('./gdrive/My Drive/develop/uni/deepl_project/data/','train.json',config['padding_size'])\n",
        "(x_train, y_train), (x_val, y_val) = dataloader.load_data()\n",
        "\n",
        "# restructure data (batch_size, count of subsequences, subsequence size, features, channels)\n",
        "subseq_size = config['subseq_size']\n",
        "x_train=x_train.reshape((x_train.shape[0], int(config['padding_size']/subseq_size), subseq_size, x_train.shape[2]))\n",
        "x_val=x_val.reshape((x_val.shape[0], int(config['padding_size']/subseq_size), subseq_size, x_val.shape[2]))\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], x_train.shape[2], x_train.shape[3],1))\n",
        "x_val = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], x_val.shape[2], x_val.shape[3],1))\n",
        "\n",
        "# Set the shapes\n",
        "target_shape_train = y_train.shape\n",
        "target_shape_test = y_val.shape \n",
        "input_shape_total = x_train.shape\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# print the shapes\n",
        "print(target_shape_train)\n",
        "print(target_shape_test)\n",
        "print(input_shape_total)\n",
        "print(input_shape)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7020, 4)\n",
            "(779, 4)\n",
            "(7020, 100, 10, 26, 1)\n",
            "(100, 10, 26, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaa-ctoLSK36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNNLSTMClassifier():\n",
        "    def __init__(self):\n",
        "        cnn = Sequential(name=config['model_name'])\n",
        "        cnn.add(Conv2D(filters=64, kernel_size=(3,3), strides=(1,1), padding='same', data_format='channels_last'))\n",
        "        cnn.add(BatchNormalization())\n",
        "        cnn.add(Activation('elu'))\n",
        "        cnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "        cnn.add(Dropout(0.5))\n",
        "\n",
        "        cnn.add(Conv2D(filters=32, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "        cnn.add(BatchNormalization())\n",
        "        cnn.add(Activation('elu'))\n",
        "        cnn.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
        "        cnn.add(Dropout(0.25))\n",
        "\n",
        "        cnn.add(Flatten())\n",
        "\n",
        "        #prepare stacked LSTM\n",
        "        model = Sequential()\n",
        "        model.add(TimeDistributed(cnn,input_shape=input_shape))\n",
        "        model.add(LSTM(config['lstm_cells'],return_sequences=True))\n",
        "        model.add(LSTM(config['lstm_cells'],return_sequences=True))\n",
        "\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(config['num_classes'],activation='softmax')) \n",
        "\n",
        "        # Model compilation\n",
        "        #opt = optimizers.Adam(lr=0.001, beta_1=0.9,  beta_2=0.999, amsgrad=False)\n",
        "        opt = optimizers.SGD(lr=config['learning_rate_max'], momentum=0.9, nesterov=False)\n",
        "        model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "        self.model = model\n",
        "\n",
        "    def load(self):\n",
        "        return self.model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAzgtSxoOQub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "9b7d8471-fae8-4017-8d19-0451c29c2a2f"
      },
      "source": [
        "# load model\n",
        "model = CNNLSTMClassifier().load()\n",
        "\n",
        "# Summary\n",
        "model.summary()\n",
        "\n",
        "# Model Training\n",
        "lr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=20, min_lr=0.000001)\n",
        "# Please change the model name accordingly.\n",
        "# Name format datatype_sequencelength_featurelength_architecture_layercount_epochs_accuracy:\n",
        "mcp_save = ModelCheckpoint('./gdrive/My Drive/develop/uni/deepl_project/runs/models/'+ config['model_name'], save_best_only=True, monitor='val_categorical_accuracy', mode='max')\n",
        "cnnhistory=model.fit(x_train, y_train, batch_size=config['batch_size'], epochs=config['num_epochs'],validation_data=(x_val, y_val), callbacks=[mcp_save, lr_reduce])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_2 (TimeDist (None, 100, 384)          19488     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100, 26)           42744     \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 100, 26)           5512      \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 2600)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4)                 10404     \n",
            "=================================================================\n",
            "Total params: 78,148\n",
            "Trainable params: 77,956\n",
            "Non-trainable params: 192\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUZhBBGvnoU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max(cnnhistory.history['val_categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heW-_kGLnqvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting the Train Valid Loss Graph\n",
        "\n",
        "plt.plot(cnnhistory.history['categorical_accuracy'])\n",
        "plt.plot(cnnhistory.history['val_categorical_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pLxxcYwnq4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting the Train Valid Loss Graph\n",
        "\n",
        "plt.plot(cnnhistory.history['loss'])\n",
        "plt.plot(cnnhistory.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show("
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKjruDhGc7aj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model = load_model('./gdrive/My Drive/develop/uni/deepl_project/runs/models/Audio_same500_26_cnnlstm_2L1L_SGD_e300.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvCTZQDJdfOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9b40374-7f64-4c03-9155-5ccfbbcf373a"
      },
      "source": [
        "#model.evaluate(x_val, y_val, verbose = 0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8207830921370196, 0.6752246472128549]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxNvBk5Inq__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe66c990-c738-42ec-d074-9a24dece2526"
      },
      "source": [
        "dataloader_dev = KerasDataloader('./gdrive/My Drive/develop/uni/deepl_project/data/','dev.json', config['padding_size'], False)\n",
        "(x_dev, y_train), (x_val, y_val) = dataloader_dev.load_data()\n",
        "x_dev=x_dev.reshape((x_dev.shape[0], int(config['padding_size']/subseq_size), subseq_size, x_dev.shape[2]))\n",
        "x_dev = x_dev.reshape((x_dev.shape[0], x_dev.shape[1], x_dev.shape[2],x_dev.shape[3], 1))\n",
        "\n",
        "predictions = model.predict(x_dev)\n",
        "print(predictions.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3342, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_TtVDm8nu7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataloader_dev.save_predictions(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}